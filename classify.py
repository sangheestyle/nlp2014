from collections import defaultdict
from csv import DictReader, DictWriter

import operator
import nltk
from nltk.corpus import wordnet as wn
from nltk.tokenize import TreebankWordTokenizer

kTOKENIZER = TreebankWordTokenizer()
TOPGUESSES = 40
def morphy_stem(word):
    """
    Simple stemmer
    """
    stem = wn.morphy(word)
    if stem:
        return stem.lower()
    else:
        return word.lower()

def compose_top_scores(qt_dict, ir_dict, n):
    """
        Given two sets of guesses, this will return a dictionaty containing
        the n top guesses of the two models
    """
    h = n - (n/2)
    top_guesses = {}
    for i in xrange(h):
        top_guesses[qt_dict[i][0]] = qt_dict[i][1]
    i = 0
    c = 0
    
    while (i+h) < n:
        while True:
            if ir_dict[c][0] not in top_guesses:
                break
            c += 1
        top_guesses[ir_dict[c][0]] = ir_dict[c][1]
        i += 1

    return top_guesses

def get_answer(qt_dict, ir_dict, n, rank):
    """
        This will return the answer ranked "rank" among the top guesses generated by compose_top_scores
    """
    """
    if rank < 0:
        #print "#"
        return qt_dict[0][0]
    """
    h = n - (n/2)
    if rank < h:
        return qt_dict[rank][0]
    else:
        return ir_dict[rank-h][0]

def form_dict(vals):
    d = defaultdict(float)
    for jj in vals.split(", "):
        key, val = jj.split(":")
        d[key.strip()] = float(val)
    return d


class FeatureExtractor:
    def __init__(self):
        """
        You may want to add code here
        """
        
        None
    
    def features(self, dict):
        d = defaultdict(int)
        """
        for ii in kTOKENIZER.tokenize(dict['Question Text']):
            d[morphy_stem(ii)] += 1
        """
        qd = form_dict(dict['QANTA Scores'])
        wd = form_dict(dict['IR_Wiki Scores'])
        sp = int(dict['Sentence Position'])
    
    
    
        
        sorted_qd = sorted(qd.items(), key=operator.itemgetter(1), reverse=True)
        sorted_wd = sorted(wd.items(), key=operator.itemgetter(1), reverse=True)
        overlap = 0
        
        for qg in xrange(len(sorted_qd)):
            if sorted_qd[qg][0] == sorted_wd[0][0]:
                overlap = 1
                if  (sorted_qd[0][1] - sorted_qd[1][1]) < 0.15:
                    d['Top IR Overlap'] += qg
                else:
                    d['Top IR Overlap'] -= qg
                break

    
        if overlap == 0:
            if sorted_qd[0][1] < 0.05 and sorted_wd[0][1] > 4.0:
                d['Top IR'] += 1
            if sp == 0 and sorted_qd[0][1] < 0.1:
                d['Top_IR'] += int(sorted_wd[0][1])


        """
        for rg in xrange(len(sorted_wd)):
            if sorted_wd[rg][0] == sorted_qd[0][0]:
                d['Top Q Overlap'] += len(sorted_wd)-rg
        """
        for i in xrange(4*sp):
            if i < len(sorted_qd) and sorted_qd[i][0] == sorted_wd[i][0]:
                d['Equal Rank'] += i + 2

        if sorted_qd[0][1] > 0.74:
            d['Q Score'] = 0
        elif sorted_qd[0][1] > 0.39:
            d['Q Score'] = 1
        else:
            d['Q Score'] = -1


        if sorted_wd[0][1] > 20.0 and sorted_qd[0][1] < 0.1:
            d['IR Score'] = TOPGUESSES
        
        d['Guesses vs SP'] = TOPGUESSES - sp
        d['Sentence Position'] = sp

        return d

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='Process some integers.')
    parser.add_argument('--subsample', type=float, default=1.0,
                        help='subsample this amount')
    args = parser.parse_args()
    
    # Create feature extractor (you may want to modify this)
    fe = FeatureExtractor()
    
    # Read in training data
    train = DictReader(open("new_train_"+str(TOPGUESSES)+".csv", 'r'))
    
    # Split off dev section
    dev_train = []
    dev_test = []
    train_set = []
    all_set = []
    for ii in train:
        if args.subsample < 1.0 and int(ii['Question ID']) % 100 > 100 * args.subsample:
            continue

        dict = {}
        dict['Question Text'] = ii['Question Text']
        dict['Question ID'] = ii['Question ID']
        dict['QANTA Scores'] = ii['QANTA Scores']
        dict['IR_Wiki Scores'] = ii['IR_Wiki Scores']
        dict['Sentence Position'] = ii['Sentence Position']
        dict['category'] = ii['category']
        feat = fe.features(dict)
        dict['Answer Rank'] = ii['Answer Rank']
        dict['Answer'] = ii['Answer']
        train_set.append((feat, ii['Answer Rank']))
        if int(ii['Question ID']) % 5 == 0:
            
            dev_test.append((feat, ii['Answer Rank'], ii['Question ID'], ii['Sentence Position']))
            all_set.append((dict))
                
        else:
            dev_train.append((feat, ii['Answer Rank']))
        

    # Train a classifier
    print("Training classifier ...")
    classifier = nltk.classify.NaiveBayesClassifier.train(dev_train)
    #classifier = nltk.classify.MaxentClassifier.train(dev_train, 'IIS', trace=3, max_iter=100)
    columns = ['Question ID', 'Question Text', 'Sentence Position','Correct Answer', 'Our Guess', 'QANTA Scores', 'IR_Wiki Scores', 'category']
    incorrect_stats = DictWriter(open('incorrect_stats', 'w'), columns)
    incorrect_stats.writeheader()
    """
    right = 0
    total = len(dev_test)

    for ii in dev_test:
        prediction = classifier.classify(ii[0])
        if prediction == ii[1]:
            right += 1

    print("Accuracy on dev: %f" % (float(right) / float(total)))
    """
    right = 0
    total = len(all_set)
    correct = DictWriter(open('correct_pred.csv', 'w'), ['Question ID','Question Text','Sentence Position','Answer','Answer Rank','Prediction','QANTA','IR_Wiki','category'])
    incorrect = DictWriter(open('incorrect_pred.csv', 'w'), ['Question ID','Question Text','Sentence Position','Answer','Answer Rank','Prediction','QANTA','IR_Wiki','category'])
    incorrect.writeheader()
    correct.writeheader()
    for ii in all_set:
        dict = {}
        dict['Question Text'] = ii['Question Text']
        dict['Question ID'] = ii['Question ID']
        dict['QANTA Scores'] = ii['QANTA Scores']
        dict['IR_Wiki Scores'] = ii['IR_Wiki Scores']
        dict['Sentence Position'] = ii['Sentence Position']
        dict['category'] = ii['category']
        feat = fe.features(dict)
        dict['Answer'] = ii['Answer']
        dict['Answer Rank'] = ii['Answer Rank']
        prediction = classifier.classify(feat)
        qd = form_dict(dict['QANTA Scores'])
        wd = form_dict(dict['IR_Wiki Scores'])
        sorted_qd = sorted(qd.items(), key=operator.itemgetter(1), reverse=True)
        sorted_wd = sorted(wd.items(), key=operator.itemgetter(1), reverse=True)

        if prediction == ii['Answer Rank']:
            right += 1
            correct.writerow({'Question ID':dict['Question ID'],'Question Text':dict['Question Text'],'Sentence Position':dict['Sentence Position'],'Answer':dict['Answer'],'Answer Rank':dict['Answer Rank'],'Prediction':prediction,'QANTA':sorted_qd,'IR_Wiki':sorted_wd,'category':dict['category']})
        else:
            incorrect.writerow({'Question ID':dict['Question ID'],'Question Text':dict['Question Text'],'Sentence Position':dict['Sentence Position'],'Answer':dict['Answer'],'Answer Rank':dict['Answer Rank'],'Prediction':prediction,'QANTA':sorted_qd,'IR_Wiki':sorted_wd,'category':dict['category']})
    print("Accuracy on dev: %f" % (float(right) / float(total)))
    print "\nLength of dev set:\t",total,"\nIncorrect pred:\t\t",(total - right)

    # Retrain on all data
    classifier = nltk.classify.NaiveBayesClassifier.train(train_set)
    #classifier = nltk.classify.MaxentClassifier.train(dev_train+ dev_test, 'IIS', trace=3, max_iter=1000)
    # Read in test section
    test = {}
    for ii in DictReader(open("test.csv")):
        dict = {}
        dict['Question Text'] = ii['Question Text']
        dict['Question ID'] = ii['Question ID']
        dict['QANTA Scores'] = ii['QANTA Scores']
        dict['IR_Wiki Scores'] = ii['IR_Wiki Scores']
        dict['Sentence Position'] = ii['Sentence Position']
        dict['category'] = ii['category']
        qd = form_dict(dict['QANTA Scores'])
        wd = form_dict(dict['IR_Wiki Scores'])
        sorted_qd = sorted(qd.items(), key=operator.itemgetter(1), reverse=True)
        sorted_wd = sorted(wd.items(), key=operator.itemgetter(1), reverse=True)
        rank = int(classifier.classify(fe.features(dict)))
        #print rank
        #test[ii['Question ID']] = get_answer(sorted_qd, sorted_qd, TOPGUESSES, rank)
        #print rank
        if rank < 20:
            if rank < 0:
                rank = 0
            test[ii['Question ID']] = sorted_qd[rank][0]
        else:
            test[ii['Question ID']] = sorted_wd[rank-TOPGUESSES][0]
        

    # Write predictions
    o = DictWriter(open('pred.csv', 'w'), ['Question ID', 'Answer'])
    o.writeheader()
    for ii in sorted(test):
        o.writerow({'Question ID': ii, 'Answer': test[ii]})







